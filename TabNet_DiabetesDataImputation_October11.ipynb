{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8483931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (Before Missing Values):\n",
      "        age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
      "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
      "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
      "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
      "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
      "\n",
      "         s4        s5        s6  \n",
      "0 -0.002592  0.019907 -0.017646  \n",
      "1 -0.039493 -0.068332 -0.092204  \n",
      "2 -0.002592  0.002861 -0.025930  \n",
      "3  0.034309  0.022688 -0.009362  \n",
      "4 -0.002592 -0.031988 -0.046641  \n",
      "\n",
      "Input Data with Missing Values:\n",
      "        age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
      "1 -0.001882       NaN -0.051474 -0.026328       NaN       NaN  0.074412   \n",
      "2  0.085299  0.050680       NaN -0.005670 -0.045599       NaN -0.032356   \n",
      "3       NaN -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
      "4  0.005383 -0.044642 -0.036385  0.021872       NaN       NaN  0.008142   \n",
      "\n",
      "         s4        s5        s6  \n",
      "0 -0.002592  0.019907       NaN  \n",
      "1 -0.039493 -0.068332 -0.092204  \n",
      "2 -0.002592       NaN -0.025930  \n",
      "3       NaN  0.022688 -0.009362  \n",
      "4 -0.002592 -0.031988 -0.046641  \n",
      "\n",
      "After Normalizing Input Data:\n",
      "        age  sex       bmi        bp        s1        s2        s3        s4  \\\n",
      "0  0.666667  1.0  0.580913  0.609375  0.295567  0.256972  0.210526  0.282087   \n",
      "1  0.483333  NaN  0.145228  0.390625       NaN       NaN  0.631579  0.141044   \n",
      "2  0.883333  1.0       NaN  0.484375  0.290640       NaN  0.250000  0.282087   \n",
      "3       NaN  0.0  0.298755  0.343750  0.497537  0.447211  0.236842       NaN   \n",
      "4  0.516667  0.0  0.203320  0.609375       NaN       NaN  0.394737  0.282087   \n",
      "\n",
      "         s5        s6  \n",
      "0  0.562217       NaN  \n",
      "1  0.222437  0.166667  \n",
      "2       NaN  0.409091  \n",
      "3  0.572923  0.469697  \n",
      "4  0.362385  0.333333  \n",
      "\n",
      "Filled Missing Values with Zero Placeholder:\n",
      "        age  sex       bmi        bp        s1        s2        s3        s4  \\\n",
      "0  0.666667  1.0  0.580913  0.609375  0.295567  0.256972  0.210526  0.282087   \n",
      "1  0.483333  0.0  0.145228  0.390625  0.000000  0.000000  0.631579  0.141044   \n",
      "2  0.883333  1.0  0.000000  0.484375  0.290640  0.000000  0.250000  0.282087   \n",
      "3  0.000000  0.0  0.298755  0.343750  0.497537  0.447211  0.236842  0.000000   \n",
      "4  0.516667  0.0  0.203320  0.609375  0.000000  0.000000  0.394737  0.282087   \n",
      "\n",
      "         s5        s6  \n",
      "0  0.562217  0.000000  \n",
      "1  0.222437  0.166667  \n",
      "2  0.000000  0.409091  \n",
      "3  0.572923  0.469697  \n",
      "4  0.362385  0.333333  \n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 34.85141|  0:00:00s\n",
      "epoch 1  | loss: 20.23025|  0:00:00s\n",
      "epoch 2  | loss: 13.06177|  0:00:00s\n",
      "epoch 3  | loss: 8.40675 |  0:00:00s\n",
      "epoch 4  | loss: 5.70412 |  0:00:00s\n",
      "epoch 5  | loss: 5.31847 |  0:00:00s\n",
      "epoch 6  | loss: 3.55638 |  0:00:00s\n",
      "epoch 7  | loss: 3.53446 |  0:00:00s\n",
      "epoch 8  | loss: 2.5662  |  0:00:00s\n",
      "epoch 9  | loss: 2.09792 |  0:00:00s\n",
      "epoch 10 | loss: 2.03352 |  0:00:00s\n",
      "epoch 11 | loss: 1.86319 |  0:00:00s\n",
      "epoch 12 | loss: 1.75679 |  0:00:00s\n",
      "epoch 13 | loss: 1.55641 |  0:00:00s\n",
      "epoch 14 | loss: 1.40693 |  0:00:00s\n",
      "epoch 15 | loss: 1.32563 |  0:00:00s\n",
      "epoch 16 | loss: 1.34998 |  0:00:00s\n",
      "epoch 17 | loss: 1.28513 |  0:00:00s\n",
      "epoch 18 | loss: 1.29186 |  0:00:00s\n",
      "epoch 19 | loss: 1.1948  |  0:00:00s\n",
      "epoch 20 | loss: 1.1606  |  0:00:00s\n",
      "epoch 21 | loss: 1.14615 |  0:00:00s\n",
      "epoch 22 | loss: 1.11519 |  0:00:00s\n",
      "epoch 23 | loss: 1.10182 |  0:00:00s\n",
      "epoch 24 | loss: 1.0303  |  0:00:00s\n",
      "epoch 25 | loss: 1.12591 |  0:00:00s\n",
      "epoch 26 | loss: 1.03691 |  0:00:00s\n",
      "epoch 27 | loss: 1.0638  |  0:00:00s\n",
      "epoch 28 | loss: 1.0477  |  0:00:00s\n",
      "epoch 29 | loss: 1.0038  |  0:00:00s\n",
      "epoch 30 | loss: 1.02785 |  0:00:00s\n",
      "epoch 31 | loss: 1.08897 |  0:00:00s\n",
      "epoch 32 | loss: 1.04897 |  0:00:00s\n",
      "epoch 33 | loss: 1.05807 |  0:00:00s\n",
      "epoch 34 | loss: 1.05458 |  0:00:00s\n",
      "epoch 35 | loss: 1.00106 |  0:00:00s\n",
      "epoch 36 | loss: 1.05181 |  0:00:00s\n",
      "epoch 37 | loss: 0.98652 |  0:00:00s\n",
      "epoch 38 | loss: 0.99199 |  0:00:00s\n",
      "epoch 39 | loss: 1.00856 |  0:00:00s\n",
      "epoch 40 | loss: 0.99287 |  0:00:00s\n",
      "epoch 41 | loss: 0.99039 |  0:00:00s\n",
      "epoch 42 | loss: 0.99721 |  0:00:00s\n",
      "epoch 43 | loss: 1.0078  |  0:00:00s\n",
      "epoch 44 | loss: 0.98761 |  0:00:00s\n",
      "epoch 45 | loss: 1.0303  |  0:00:00s\n",
      "epoch 46 | loss: 0.91013 |  0:00:00s\n",
      "epoch 47 | loss: 1.01954 |  0:00:00s\n",
      "epoch 48 | loss: 0.99311 |  0:00:00s\n",
      "epoch 49 | loss: 0.98386 |  0:00:00s\n",
      "\n",
      "Pretrained TabNet Model:\n",
      "\n",
      "True Missing Values:\n",
      "[[0.66666667 1.         0.58091286 ... 0.28208745 0.562217   0.        ]\n",
      " [0.48333333 0.         0.14522822 ... 0.14104372 0.22243673 0.16666667]\n",
      " [0.88333333 1.         0.         ... 0.28208745 0.         0.40909091]\n",
      " ...\n",
      " [0.68333333 1.         0.         ... 0.24964739 0.30503001 0.56060606]\n",
      " [0.28333333 0.         0.49377593 ... 0.39351199 0.65702552 0.        ]\n",
      " [0.28333333 0.         0.06224066 ... 0.14104372 0.46930394 0.        ]]\n",
      "\n",
      "Reconstructed Data:\n",
      "        age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0  0.666667  1.000000  0.580913  0.609375  0.295567  0.256972  0.210526   \n",
      "1  0.483333  0.396268  0.145228  0.390625  0.431096  0.213366  0.631579   \n",
      "2  0.883333  1.000000  0.227612  0.484375  0.290640  0.384487  0.250000   \n",
      "3  0.325128  0.440685  0.298755  0.343750  0.497537  0.447211  0.236842   \n",
      "4  0.516667  0.474379  0.203320  0.609375  0.521803  0.161130  0.394737   \n",
      "\n",
      "         s4        s5        s6  \n",
      "0  0.282087  0.562217  0.537696  \n",
      "1  0.141044  0.222437  0.166667  \n",
      "2  0.282087  0.383234  0.409091  \n",
      "3  0.294836  0.572923  0.469697  \n",
      "4  0.282087  0.362385  0.333333  \n",
      "\n",
      "Imputed Values:\n",
      "[[0.66666667 1.         0.58091286 ... 0.28208745 0.562217   0.53769606]\n",
      " [0.48333333 0.39626834 0.14522822 ... 0.14104372 0.22243673 0.16666667]\n",
      " [0.88333333 1.         0.2276125  ... 0.28208745 0.38323385 0.40909091]\n",
      " ...\n",
      " [0.68333333 1.         0.29289383 ... 0.24964739 0.30503001 0.56060606]\n",
      " [0.28333333 0.44520897 0.49377593 ... 0.39351199 0.65702552 0.4181245 ]\n",
      " [0.28333333 0.33245349 0.06224066 ... 0.14104372 0.46930394 0.32379529]]\n",
      "\n",
      "Original Data (Before Missing Values):\n",
      "        age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
      "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
      "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
      "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
      "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
      "\n",
      "         s4        s5        s6  \n",
      "0 -0.002592  0.019907 -0.017646  \n",
      "1 -0.039493 -0.068332 -0.092204  \n",
      "2 -0.002592  0.002861 -0.025930  \n",
      "3  0.034309  0.022688 -0.009362  \n",
      "4 -0.002592 -0.031988 -0.046641  \n",
      "\n",
      "Denormalized Reconstructed Data:\n",
      "        age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
      "1 -0.001882 -0.006869 -0.051474 -0.026328 -0.006368 -0.048531  0.074412   \n",
      "2  0.085299  0.050680 -0.030075 -0.005670 -0.045599  0.005270 -0.032356   \n",
      "3 -0.036363 -0.002635 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
      "4  0.005383  0.000577 -0.036385  0.021872  0.018968 -0.064954  0.008142   \n",
      "\n",
      "         s4        s5        s6  \n",
      "0 -0.002592  0.019907  0.009228  \n",
      "1 -0.039493 -0.068332 -0.092204  \n",
      "2 -0.002592 -0.026573 -0.025930  \n",
      "3  0.000743  0.022688 -0.009362  \n",
      "4 -0.002592 -0.031988 -0.046641  \n",
      "\n",
      "RMSE between Original Data and Denormalized Reconstructed Data: 0.031926904740095685\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the Diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "data = diabetes.data\n",
    "feature_names = ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data, columns=feature_names)\n",
    "\n",
    "# Make a copy of the original data before introducing missing values\n",
    "original_data = df.copy()\n",
    "print(\"Original Data (Before Missing Values):\")\n",
    "print(original_data.head())\n",
    "\n",
    "# Introduce artificial missing values\n",
    "missing_fraction = 0.2\n",
    "mask = np.random.rand(*data.shape) < missing_fraction\n",
    "df[mask] = np.nan\n",
    "\n",
    "# Print the input dataset with missing values\n",
    "print(\"\\nInput Data with Missing Values:\")\n",
    "print(df.head())\n",
    "\n",
    "# Normalize the dataset\n",
    "scaler = MinMaxScaler()\n",
    "numeric_cols = df.columns\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "print(\"\\nAfter Normalizing Input Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Fill missing values with zero\n",
    "df[numeric_cols] = df[numeric_cols].fillna(0)\n",
    "\n",
    "print(\"\\nFilled Missing Values with Zero Placeholder:\")\n",
    "print(df.head())\n",
    "\n",
    "# Define and pretrain the TabNet model\n",
    "pretrained_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='sparsemax',\n",
    "    # n_d=32,  # Adjust the number of decision steps as needed\n",
    "    # n_a=32   # Adjust the number of features shared as needed\n",
    ")\n",
    "\n",
    "max_epochs = 50\n",
    "pretrained_model.fit(\n",
    "    df[numeric_cols].values,\n",
    "    max_epochs=max_epochs\n",
    ")\n",
    "\n",
    "print(\"\\nPretrained TabNet Model:\")\n",
    "\n",
    "def tabnet_recon(df, network, missing_value_placeholder=0, numeric_cols=None, scaler=None):\n",
    "    # Ensure numeric_cols and scaler are provided\n",
    "    if numeric_cols is None or scaler is None:\n",
    "        raise ValueError(\"Please provide numeric_cols and scaler.\")\n",
    "    \n",
    "    # Copy the input data\n",
    "    df_tab = df.copy()\n",
    "    \n",
    "    # Identify the rows and columns where the placeholder value exists\n",
    "    missing_mask = (df_tab[numeric_cols] == missing_value_placeholder)\n",
    "    \n",
    "    # Normalize the input data\n",
    "    df_tab[numeric_cols] = scaler.transform(df_tab[numeric_cols])\n",
    "    \n",
    "    # Convert input data to tensors for use in the TabNet network\n",
    "    inputData = torch.tensor(df_tab[numeric_cols].values, dtype=torch.float32)\n",
    "    \n",
    "    # Pass the input data through the TabNet network\n",
    "    results = network.predict(inputData)\n",
    "    \n",
    "    # Ensure results is a NumPy array\n",
    "    if isinstance(results, tuple):\n",
    "        results = results[0]  # Use the first element of the tuple\n",
    "    elif isinstance(results, torch.Tensor):\n",
    "        results = results.detach().numpy()  # Convert to NumPy array\n",
    "        \n",
    "    df_tab[numeric_cols] = results\n",
    "    \n",
    "    # Apply the reconstructed values only to the missing positions\n",
    "    df_tab[numeric_cols] = np.where(missing_mask, df_tab[numeric_cols], df[numeric_cols] )\n",
    "    \n",
    "    return df_tab\n",
    "\n",
    "# Extract true missing values before filling\n",
    "true_missing_values = df[numeric_cols].values\n",
    "\n",
    "print('\\nTrue Missing Values:')\n",
    "print(true_missing_values)\n",
    "\n",
    "# Reconstruct missing values using the pretrained model\n",
    "reconstructed_data = tabnet_recon(\n",
    "    df,\n",
    "    network=pretrained_model,\n",
    "    numeric_cols=numeric_cols,  # Provide the numeric_cols\n",
    "    scaler=scaler  # Provide the scaler\n",
    ")\n",
    "\n",
    "print('\\nReconstructed Data:')\n",
    "print(reconstructed_data.head())\n",
    "\n",
    "# Extract imputed values\n",
    "imputed_values = reconstructed_data[numeric_cols].values\n",
    "\n",
    "print('\\nImputed Values:')\n",
    "print(imputed_values)\n",
    "\n",
    "# Denormalize the reconstructed data\n",
    "reconstructed_data[numeric_cols] = scaler.inverse_transform(reconstructed_data[numeric_cols])\n",
    "\n",
    "# Print the original data (before missing values) and reconstructed data\n",
    "print(\"\\nOriginal Data (Before Missing Values):\")\n",
    "print(original_data.head())\n",
    "\n",
    "print(\"\\nDenormalized Reconstructed Data:\")\n",
    "print(reconstructed_data.head())\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(np.mean((original_data[numeric_cols].values - reconstructed_data[numeric_cols].values) ** 2))\n",
    "\n",
    "# Print the RMSE\n",
    "print(\"\\nRMSE between Original Data and Denormalized Reconstructed Data:\", rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
